# -*- coding: utf-8 -*-
"""Diabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rCrprXYVfQ54TGRzKO5JYCagV5U2rS3N

# Importing the required libraries
"""

import sklearn
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix

"""# Importing the dataset"""

df = pd.read_csv("diabetes.csv")
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values
df

"""# Clearing the data
value of Blood Pressure can not be zero thus changing it to Nan
"""

df.iloc[:,2]   = df.iloc[:,2].replace(0, np.nan)
impute = SimpleImputer(missing_values=np.nan, strategy="mean")
impute = impute.fit(df.iloc[:,2:3] )
df.iloc[:,2:3] = impute.transform(df.iloc[:,2:3])
df.head(30)

"""# Scaling down our data"""

scaler = StandardScaler()
scaler.fit(df.drop('Outcome',axis=1))
scaled_features = scaler.transform(df.drop('Outcome',axis=1))
scaler_trans = pd.DataFrame(scaled_features,columns=df.columns[:-1])
scaler_trans.head()

"""# Finding out right model
The KNN model or SVM would fit the best no straight line can distinguish so logistic regresson is out, Random Forest will require more distinguishable data so it is also out.
"""

sns.pairplot(df,hue = 'Outcome' )

"""# Splitting the data"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)

"""#Feature Scaling"""

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# Fitting Classifier to training set"""

classifier = SVC(kernel='rbf',random_state=0)
classifier.fit(X_train, y_train)

"""# Predicting the Test set results"""

y_pred = classifier.predict(X_test)

"""# Making the Confusion Matrix"""

cm = confusion_matrix(y_test, y_pred)
print(cm)

y_pred,y_test