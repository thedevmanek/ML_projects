# -*- coding: utf-8 -*-
"""Diabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rCrprXYVfQ54TGRzKO5JYCagV5U2rS3N

# Importing the required libraries
"""

import sklearn
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix

"""# Importing the dataset"""

df = pd.read_csv("diabetes.csv")
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values
df

"""# Scaling down our data"""

scaler = StandardScaler()
scaler.fit(df.drop('Outcome',axis=1))
scaled_features = scaler.transform(df.drop('Outcome',axis=1))
scaler_trans = pd.DataFrame(scaled_features,columns=df.columns[:-1])
scaler_trans.head()

"""# Finding out right model
The KNN model would fit the best no straight line can distinguish so logistic regresson is out, Random Forest will require more distinguishable data so it is also out.
"""

sns.pairplot(df,hue = 'Outcome' )

"""# Splitting the data"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)

"""#Feature Scaling"""

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# Fitting Classifier to training set"""

classifier = KNeighborsClassifier(n_neighbors=7, metric="minkowski", p=2)
classifier.fit(X_train, y_train)

"""# Predicting the Test set results"""

y_pred = classifier.predict(X_test)

"""# Making the Confusion Matrix"""

cm = confusion_matrix(y_test, y_pred)
print(cm)

y_pred,y_test